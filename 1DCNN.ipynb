{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:03:54.324951Z",
     "iopub.status.busy": "2023-05-31T19:03:54.324564Z",
     "iopub.status.idle": "2023-05-31T19:03:54.899344Z",
     "shell.execute_reply": "2023-05-31T19:03:54.898575Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"font\", family=\"cm\")\n",
    "plt.rcParams[\"grid.color\"] = (0.5, 0.5, 0.5, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:03:54.903288Z",
     "iopub.status.busy": "2023-05-31T19:03:54.902548Z",
     "iopub.status.idle": "2023-05-31T19:05:40.414483Z",
     "shell.execute_reply": "2023-05-31T19:05:40.413793Z"
    }
   },
   "outputs": [],
   "source": [
    "X_dataframe = pd.read_csv(\"/mnt/ferracci/features_dataframe_new.csv.gz\")\n",
    "X = np.load(\"/mnt/ferracci/features_new.npz\", allow_pickle=True)['a']\n",
    "y = np.array(pd.read_csv(\"/mnt/ferracci/targets_dataframe_new.csv.gz\")[\"Qedep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:40.418845Z",
     "iopub.status.busy": "2023-05-31T19:05:40.418093Z",
     "iopub.status.idle": "2023-05-31T19:05:48.568301Z",
     "shell.execute_reply": "2023-05-31T19:05:48.567617Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import optuna\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchmetrics import MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "mean_squared_error = MeanSquaredError().to(device)\n",
    "\n",
    "# normalize dataset \n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train_std = np.std(X_train, axis=0)\n",
    "X_train_norm = (X_train - X_train_mean) / X_train_std\n",
    "X_valid_norm = (X_valid - X_train_mean) / X_train_std \n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train_norm), torch.Tensor(y_train))\n",
    "valid_dataset = TensorDataset(torch.Tensor(X_valid_norm), torch.Tensor(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.572223Z",
     "iopub.status.busy": "2023-05-31T19:05:48.571389Z",
     "iopub.status.idle": "2023-05-31T19:05:48.575239Z",
     "shell.execute_reply": "2023-05-31T19:05:48.574757Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.578135Z",
     "iopub.status.busy": "2023-05-31T19:05:48.577652Z",
     "iopub.status.idle": "2023-05-31T19:05:48.587306Z",
     "shell.execute_reply": "2023-05-31T19:05:48.586825Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inspired by a few winning solutions in kaggle competitions, 1DCNNs can perform quite well on tabular data. The idea is to add \n",
    "a single fully connected layer between the input and the first convolution, so that the network can learn by itself a spacial \n",
    "representation of the features on which the convolutional layers can then work.\n",
    "\"\"\"\n",
    "class tabCNN(nn.Module):\n",
    "    def __init__(self, n_features, dropout_rate, activation_name):\n",
    "        super().__init__()\n",
    "        self.activation_name = activation_name\n",
    "        \n",
    "        # dense layer with 512 units to learn the spacial representation of features\n",
    "        self.batch_norm1 = nn.BatchNorm1d(n_features)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(n_features, 512))\n",
    "\n",
    "        # first convolution after reshaping to 32*16 --> 64*16\n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(32)\n",
    "        self.dropout_c1 = nn.Dropout(dropout_rate)\n",
    "        self.conv1 = nn.utils.weight_norm(nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1, bias=False), dim=None)\n",
    "\n",
    "        # adaptive average pooling --> 64*8\n",
    "        self.average_pool_c1 = nn.AdaptiveAvgPool1d(output_size=8)\n",
    "\n",
    "        # 3 successive convolutions --> 64*8\n",
    "        self.batch_norm_c2_1 = nn.BatchNorm1d(64)\n",
    "        self.dropout_c2_1 = nn.Dropout(dropout_rate)\n",
    "        self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1, bias=True), dim=None)\n",
    "\n",
    "        self.batch_norm_c2_2 = nn.BatchNorm1d(64)\n",
    "        self.dropout_c2_2 = nn.Dropout(dropout_rate)\n",
    "        self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1, bias=True), dim=None)\n",
    "\n",
    "        self.batch_norm_c2_3 = nn.BatchNorm1d(64)\n",
    "        self.dropout_c2_3 = nn.Dropout(dropout_rate)\n",
    "        self.conv2_3 = nn.utils.weight_norm(nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1, bias=True), dim=None)\n",
    "        \n",
    "        # max pooling --> 64*4\n",
    "        self.max_pool_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        # flattening --> 256\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # dense layer leading to model prediction\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(256, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = get_activation_layer(self.activation_name, self.dense1(x))\n",
    "\n",
    "        x = x.reshape(x.shape[0], 32, 16)\n",
    "\n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = self.dropout_c1(x)\n",
    "        x = get_activation_layer(self.activation_name, self.conv1(x))\n",
    "\n",
    "        x = self.average_pool_c1(x)\n",
    "\n",
    "        x = self.batch_norm_c2_1(x)\n",
    "        x = self.dropout_c2_1(x)\n",
    "        x = get_activation_layer(self.activation_name, self.conv2_1(x))\n",
    "\n",
    "        x_secondary = x\n",
    "\n",
    "        x = self.batch_norm_c2_2(x)\n",
    "        x = self.dropout_c2_2(x)\n",
    "        x = get_activation_layer(self.activation_name, self.conv2_2(x))\n",
    "\n",
    "        x = self.batch_norm_c2_3(x)\n",
    "        x = self.dropout_c2_3(x)\n",
    "        x = get_activation_layer(self.activation_name, self.conv2_3(x))\n",
    "\n",
    "        x = x + x_secondary\n",
    "\n",
    "        x = self.max_pool_c2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x) \n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.589921Z",
     "iopub.status.busy": "2023-05-31T19:05:48.589439Z",
     "iopub.status.idle": "2023-05-31T19:05:48.593589Z",
     "shell.execute_reply": "2023-05-31T19:05:48.593120Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn, \n",
    "               optimizer: torch.optim.Optimizer, device=device):\n",
    "    train_loss, train_mse = 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X).squeeze()\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_mse += mean_squared_error(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(dataloader)\n",
    "    train_mse /= len(dataloader)\n",
    "    return train_loss, train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.596284Z",
     "iopub.status.busy": "2023-05-31T19:05:48.595818Z",
     "iopub.status.idle": "2023-05-31T19:05:48.599716Z",
     "shell.execute_reply": "2023-05-31T19:05:48.599234Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn, device=device):\n",
    "    valid_loss, valid_mse = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for (X, y) in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X).squeeze()\n",
    "            valid_loss += loss_fn(y_pred, y)\n",
    "            valid_mse += mean_squared_error(y_pred, y)\n",
    "\n",
    "        valid_loss /= len(dataloader)\n",
    "        valid_mse /= len(dataloader)\n",
    "        \n",
    "    return valid_loss, valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.602309Z",
     "iopub.status.busy": "2023-05-31T19:05:48.601844Z",
     "iopub.status.idle": "2023-05-31T19:05:48.604974Z",
     "shell.execute_reply": "2023-05-31T19:05:48.604519Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_activation_layer(activation_name, x):    \n",
    "    if activation_name == \"SELU\":\n",
    "        activation_layer = F.selu(x)\n",
    "    elif activation_name == \"ELU\":\n",
    "        activation_layer = F.elu(x)\n",
    "    else:\n",
    "        activation_layer = F.relu(x)\n",
    "    \n",
    "    return activation_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.607629Z",
     "iopub.status.busy": "2023-05-31T19:05:48.607111Z",
     "iopub.status.idle": "2023-05-31T19:05:48.610979Z",
     "shell.execute_reply": "2023-05-31T19:05:48.610505Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(trial, model):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "  \n",
    "    if optimizer_name == \"Adam\": \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = torch.optim.RMSprop(model.parameters())\n",
    "  \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.613586Z",
     "iopub.status.busy": "2023-05-31T19:05:48.613103Z",
     "iopub.status.idle": "2023-05-31T19:05:48.616711Z",
     "shell.execute_reply": "2023-05-31T19:05:48.616231Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scheduler(trial, optimizer):\n",
    "    scheduler_name = trial.suggest_categorical(\"scheduler\", [\"None\", \"Exp\", \"Cos\"])\n",
    "\n",
    "    if scheduler_name == \"Exp\":\n",
    "        gamma = trial.suggest_float(\"gamma\", 0.1, 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "    elif scheduler_name == \"Cos\":\n",
    "        T_max = trial.suggest_int(\"T_max\", 10, 1000)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.619430Z",
     "iopub.status.busy": "2023-05-31T19:05:48.618858Z",
     "iopub.status.idle": "2023-05-31T19:05:48.621902Z",
     "shell.execute_reply": "2023-05-31T19:05:48.621414Z"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target, epsilon=1e-7):\n",
    "    error = torch.abs((target - output) / (target + epsilon))\n",
    "    loss = torch.mean(error)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.624425Z",
     "iopub.status.busy": "2023-05-31T19:05:48.623865Z",
     "iopub.status.idle": "2023-05-31T19:05:48.629875Z",
     "shell.execute_reply": "2023-05-31T19:05:48.629420Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(best_epoch, train_losses, valid_losses, train_mses, valid_mses):\n",
    "    fig, ax_left = plt.subplots(nrows=1, ncols=1, figsize=(7,5), dpi=150)\n",
    "\n",
    "    ax_left.plot(range(best_epoch+1), np.array(train_losses[:best_epoch+1])*100, color=\"blue\", label=\"Training MAPE\")\n",
    "    ax_left.plot(range(best_epoch+1), np.array(valid_losses[:best_epoch+1])*100, color=\"red\", label=\"Validation MAPE\")\n",
    "    ax_left.set_ylim((0.0, 5))\n",
    "    ax_left.set_ylabel(\"MAPE, $\\%$ curves\", fontsize=15)\n",
    "    ax_left.set_xlabel(\"Number of epochs\", fontsize=15)\n",
    "    ax_left.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax_left.tick_params(axis=\"both\", which='minor', labelsize=12)\n",
    "\n",
    "    ax_right = ax_left.twinx()\n",
    "    ax_right.plot(range(best_epoch+1), train_mses[:best_epoch+1], color=\"orange\", label=\"Training MSE\")\n",
    "    ax_right.plot(range(best_epoch+1), valid_mses[:best_epoch+1], color=\"purple\", label=\"Validation MSE\")\n",
    "    ax_right.set_ylim((0.0, 0.1))\n",
    "    ax_right.set_ylabel(\"MSE curves\", fontsize=15, rotation=270, labelpad=20)\n",
    "    ax_right.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax_right.tick_params(axis=\"both\", which='minor', labelsize=12)\n",
    "\n",
    "    lines1, labels1 = ax_left.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_right.get_legend_handles_labels()\n",
    "    ax_left.legend(lines1 + lines2, labels1 + labels2, loc=0, fontsize=12, fancybox=False, edgecolor=\"k\")\n",
    "    ax_left.grid()\n",
    "\n",
    "    fig.savefig(\"/home/ferracci/new_dataset/images/1DCNN_learning_curve.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.2)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.632648Z",
     "iopub.status.busy": "2023-05-31T19:05:48.632133Z",
     "iopub.status.idle": "2023-05-31T19:05:48.638117Z",
     "shell.execute_reply": "2023-05-31T19:05:48.637649Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.05)\n",
    "    activation_name = trial.suggest_categorical(\"activation\", [\"ReLU\", \"SELU\", \"ELU\"]) \n",
    "\n",
    "    global model\n",
    "    model = tabCNN(162, dropout_rate, activation_name).to(device)\n",
    "    optimizer = get_optimizer(trial, model)\n",
    "    scheduler = get_scheduler(trial, optimizer)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    global best_epoch\n",
    "    best_epoch = 0\n",
    "    patience = 50\n",
    "    epochs_no_improvement = 0\n",
    "    epochs = 200\n",
    "    global train_losses, train_mses, valid_losses, valid_mses\n",
    "    train_losses, train_mses, valid_losses, valid_mses = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_mse = train_step(model=model, dataloader=train_dataloader, loss_fn=MAPELoss, \n",
    "                                           optimizer=optimizer, device=device)\n",
    "        valid_loss, valid_mse = valid_step(model=model, dataloader=valid_dataloader, loss_fn=MAPELoss, device=device)\n",
    "\n",
    "        # handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            print(f\"Trial #{trial.number}. PRUNED\")\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # manually implement early stopping\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improvement = 0\n",
    "            torch.save(model.state_dict(), f\"/mnt/ferracci/1dcnn_tuned_{trial.number}.pth\")\n",
    "        else:\n",
    "            epochs_no_improvement += 1\n",
    "        if epochs_no_improvement == patience:\n",
    "            break\n",
    "\n",
    "        trial.report(best_loss, epoch)\n",
    "        train_losses.append(train_loss.item())\n",
    "        train_mses.append(train_mse.item())\n",
    "        valid_losses.append(valid_loss.item())\n",
    "        valid_mses.append(valid_mse.item())\n",
    "\n",
    "    print(f\"Trial #{trial.number}. Best MAPE: {best_loss:.5f}.\")\n",
    "    \n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T19:05:48.640659Z",
     "iopub.status.busy": "2023-05-31T19:05:48.640215Z",
     "iopub.status.idle": "2023-06-02T02:01:41.150108Z",
     "shell.execute_reply": "2023-06-02T02:01:41.149508Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def callback(study, trial):\n",
    "    if study.best_trial == trial:\n",
    "        plot_learning_curves(best_epoch, train_losses, valid_losses, train_mses, valid_mses)\n",
    "        \n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=500, callbacks=[callback])\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"\\nBest MAPE: {trial.value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:41.153394Z",
     "iopub.status.busy": "2023-06-02T02:01:41.152827Z",
     "iopub.status.idle": "2023-06-02T02:01:41.236670Z",
     "shell.execute_reply": "2023-06-02T02:01:41.236145Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dataframe = study.trials_dataframe()\n",
    "results_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:41.239462Z",
     "iopub.status.busy": "2023-06-02T02:01:41.239066Z",
     "iopub.status.idle": "2023-06-02T02:01:41.252487Z",
     "shell.execute_reply": "2023-06-02T02:01:41.251982Z"
    }
   },
   "outputs": [],
   "source": [
    "trials = results_dataframe[(results_dataframe[\"state\"] == \"COMPLETE\") & (results_dataframe[\"value\"] < 0.015)]\n",
    "trials = trials.drop([\"number\", \"datetime_start\", \"datetime_complete\", \"duration\", \"state\", \"params_T_max\", \"params_gamma\"], axis=1)\n",
    "\n",
    "# swap columns so that mse is the last column\n",
    "columns = list(trials.columns)\n",
    "trials[columns[0]] = 100*trials[columns[0]]\n",
    "columns = [columns[2], columns[1], columns[4], columns[3], columns[5]] + [columns[0]]\n",
    "trials = trials[columns]\n",
    "labels = [\"dropout rate\", \"activation function\", \"optimizer\", \"learning rate\", \"learning scheduler\", \"MAPE, \\%\"]\n",
    "trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:41.254885Z",
     "iopub.status.busy": "2023-06-02T02:01:41.254491Z",
     "iopub.status.idle": "2023-06-02T02:01:43.331590Z",
     "shell.execute_reply": "2023-06-02T02:01:43.331015Z"
    }
   },
   "outputs": [],
   "source": [
    "from helper_functions.parallel_coordinates_plot import * \n",
    "\n",
    "fig = plot_parallel_coordinates(trials, labels, linewidth=0.8, alpha=0.8)\n",
    "fig.set_dpi(150)\n",
    "fig.supylabel(\"Hyperparameter tuning\", fontsize=15, x=0.05)\n",
    "fig.savefig(\"/home/ferracci/new_dataset/images/1DCNN_hyperparameter_tuning.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:43.336233Z",
     "iopub.status.busy": "2023-06-02T02:01:43.335685Z",
     "iopub.status.idle": "2023-06-02T02:01:43.339361Z",
     "shell.execute_reply": "2023-06-02T02:01:43.338867Z"
    }
   },
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "\n",
    "# save dictionary to a file\n",
    "with open(\"/home/ferracci/new_dataset/1dcnn_study.pkl\", \"wb\") as file:\n",
    "    pickle.dump(params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:43.341984Z",
     "iopub.status.busy": "2023-06-02T02:01:43.341545Z",
     "iopub.status.idle": "2023-06-02T02:01:43.345616Z",
     "shell.execute_reply": "2023-06-02T02:01:43.345147Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dictionary from file\n",
    "with open(\"/home/ferracci/new_dataset/1dcnn_study.pkl\", \"rb\") as file:\n",
    "    params = pickle.load(file)\n",
    "\n",
    "params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:43.364963Z",
     "iopub.status.busy": "2023-06-02T02:01:43.364518Z",
     "iopub.status.idle": "2023-06-02T02:01:43.368657Z",
     "shell.execute_reply": "2023-06-02T02:01:43.368189Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from helper_functions.model_evaluation import plot_gaussian_fit\n",
    "from helper_functions.model_evaluation import energy_res_fit\n",
    "from helper_functions.model_evaluation import get_a_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:43.370974Z",
     "iopub.status.busy": "2023-06-02T02:01:43.370536Z",
     "iopub.status.idle": "2023-06-02T02:01:48.039947Z",
     "shell.execute_reply": "2023-06-02T02:01:48.039357Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_files = list(Path(\"/mnt/ferracci/\").glob(\"features_test_*\"))\n",
    "y_test_files = list(Path(\"/mnt/ferracci/\").glob(\"targets_dataframe_test_*\"))\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for X_test_file in X_test_files:\n",
    "    X_test.append(np.load(X_test_file)[\"a\"])\n",
    "for y_test_file in y_test_files:\n",
    "    y_test.append(np.array(pd.read_csv(y_test_file)[\"Qedep\"]))\n",
    "\n",
    "energies = [0, 1, 10, 7, 6, 2, 0.1, 9, 5, 3, 8, 4, 0.3, 0.6]\n",
    "X_test = [x for _, x in sorted(zip(energies, X_test))]\n",
    "y_test = [x for _, x in sorted(zip(energies, y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:48.043176Z",
     "iopub.status.busy": "2023-06-02T02:01:48.042783Z",
     "iopub.status.idle": "2023-06-02T02:01:48.059729Z",
     "shell.execute_reply": "2023-06-02T02:01:48.059249Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dictionary from file\n",
    "with open(\"/home/ferracci/new_dataset/1dcnn_study.pkl\", \"rb\") as file:\n",
    "    params = pickle.load(file)\n",
    "    \n",
    "# load the saved model from file\n",
    "best_model = tabCNN(162, params[\"dropout_rate\"], params[\"activation\"])\n",
    "best_model.load_state_dict(torch.load(f\"/mnt/ferracci/1dcnn_tuned_{trial.number}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:01:48.062123Z",
     "iopub.status.busy": "2023-06-02T02:01:48.061735Z",
     "iopub.status.idle": "2023-06-02T02:02:06.272819Z",
     "shell.execute_reply": "2023-06-02T02:02:06.272302Z"
    }
   },
   "outputs": [],
   "source": [
    "bias, res = [], []\n",
    "err_bias, err_res = [], []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    best_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        X_test[i] = (X_test[i] - X_train_mean) / X_train_std\n",
    "        X_test[i], y_test[i] = torch.Tensor(X_test[i]).float(), torch.Tensor(y_test[i])\n",
    "        y_pred = best_model(X_test[i]).squeeze()\n",
    "        err = (y_test[i] - y_pred).numpy()\n",
    "        err = err[err - np.mean(err) < 5*np.std(err)]\n",
    "    \n",
    "    mean, std, err_mean, err_std = plot_gaussian_fit(data=err, n_bins=100, name=\"1dcnn\", index=i)\n",
    "    bias.append(100 * mean / np.mean(y_test[i].numpy()))\n",
    "    res.append(100 * std / np.mean(y_test[i].numpy()))\n",
    "    err_bias.append(100 * err_mean / np.mean(y_test[i].numpy()))\n",
    "    err_res.append(100 * err_std / np.mean(y_test[i].numpy()))\n",
    "\n",
    "# get fit parameters\n",
    "a, b, c, pcov = energy_res_fit([np.mean(y_test[i].numpy()) for i in range(1, len(y_test)-2)], res[1:-2], err_res[1:-2])\n",
    "err_a, err_b, err_c = np.sqrt(np.abs(np.diag(pcov)[0])), np.sqrt(np.abs(np.diag(pcov)[1])), np.sqrt(np.abs(np.diag(pcov)[2]))\n",
    "cov_ab, cov_ac, cov_bc = pcov[0, 1], pcov[0, 2], pcov[1, 2]\n",
    "\n",
    "print(f\"a = {a:.3f} +/- {err_a:.3f}\")\n",
    "print(f\"b = {b:.3f} +/- {err_b:.3f}\")\n",
    "print(f\"c = {c:.3f} +/- {err_c:.3f}\")\n",
    "\n",
    "a_tilde, err_a_tilde = get_a_tilde(a, b, c, err_a, err_b, err_c, cov_ab, cov_ac, cov_bc)\n",
    "print(f\"\\nÃ£ = {a_tilde:.3f} +/- {err_a_tilde:.3f}\")\n",
    "\n",
    "with open('/home/ferracci/new_dataset/1dcnn_results.txt', 'w') as f:\n",
    "    f.write(str(bias))\n",
    "    f.write('\\n')\n",
    "    f.write(str(res))\n",
    "    f.write('\\n')\n",
    "    f.write(str(err_bias))\n",
    "    f.write('\\n')\n",
    "    f.write(str(err_res))\n",
    "    f.write('\\n')\n",
    "    f.write(str([a, b, c, err_a, err_b, err_c, a_tilde, err_a_tilde]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
